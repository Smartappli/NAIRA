version: '3.8'

x-airflow-common:
  &airflow-common
  image: apache/airflow:latest
  env_file:
    - .env.dev
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: ${AIRFLOW__CORE__EXECUTOR}
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
    AIRFLOW__CELERY__RESULT_BACKEND: ${AIRFLOW__CELERY__RESULT_BACKEND}
    AIRFLOW__CELERY__BROKER_URL: ${AIRFLOW__CELERY__BROKER_URL}
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: ${AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION}
    AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES}
    AIRFLOW__API__AUTH_BACKENDS: ${AIRFLOW__API__AUTH_BACKENDS}
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: ${AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK}
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    AIRFLOW__LOGGING__LOGGING_LEVEL: ${AIRFLOW__LOGGING__LOGGING_LEVEL}
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS}
    # Pre-configured connections
    AIRFLOW_CONN_PGVECTOR_DEFAULT: ${AIRFLOW_CONN_PGVECTOR_DEFAULT}
    AIRFLOW_CONN_QDRANT_DEFAULT: ${AIRFLOW_CONN_QDRANT_DEFAULT}
    AIRFLOW_CONN_REDIS_DEFAULT: ${AIRFLOW_CONN_REDIS_DEFAULT}
    AIRFLOW_CONN_MINIO_DEFAULT: ${AIRFLOW_CONN_MINIO_DEFAULT}
    AIRFLOW_CONN_NEO4J_DEFAULT: ${AIRFLOW_CONN_NEO4J_DEFAULT}
    AIRFLOW_CONN_OLLAMA_DEFAULT: ${AIRFLOW_CONN_OLLAMA_DEFAULT}
  volumes:
    - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
    - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
    - ${AIRFLOW_PROJ_DIR:-.}/config:/opt/airflow/config
    - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
    - ${AIRFLOW_PROJ_DIR:-.}:/sources
  user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-0}"
  depends_on: &airflow-common-depends-on
    pgvector:
      condition: service_healthy
    redis:
      condition: service_healthy

services:
  # ============================================================================
  # DATABASE SERVICES
  # ============================================================================

  pgvector:
    image: pgvector/pgvector:pg17
    container_name: pgvector
    env_file:
      - .env.dev
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
      POSTGRES_HOST_AUTH_METHOD: trust
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - pgvector_data:/var/lib/postgresql/data
      - ./init-pg.sql:/docker-entrypoint-initdb.d/init-pg.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    command: >
      postgres
      -c shared_preload_libraries=vector
      -c shared_buffers=${POSTGRES_SHARED_BUFFERS:-256MB}
      -c max_connections=${POSTGRES_MAX_CONNECTIONS:-200}
      -c log_statement=all
      -c log_min_duration_statement=1000

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    env_file:
      - .env.dev
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@naira.local
      PGADMIN_DEFAULT_PASSWORD: pgadmin_secure_2024
      PGADMIN_CONFIG_SERVER_MODE: 'False'
      PGADMIN_CONFIG_MASTER_PASSWORD_REQUIRED: 'False'
    ports:
      - "${PGADMIN_PORT:-5050}:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    depends_on:
      pgvector:
        condition: service_healthy
    restart: unless-stopped

  # ============================================================================
  # CACHE & MESSAGE BROKER
  # ============================================================================

  redis:
    image: redis:8-alpine
    container_name: redis
    env_file:
      - .env.dev
    command: >
      redis-server
      --save 60 1
      --loglevel warning
      --requirepass "${REDIS_PASSWORD}"
      --maxmemory ${REDIS_MAX_MEMORY:-512mb}
      --maxmemory-policy ${REDIS_MAX_MEMORY_POLICY:-allkeys-lru}
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  redisinsight:
    image: redis/redisinsight:latest
    container_name: redisinsight
    env_file:
      - .env.dev
    ports:
      - "${REDISINSIGHT_PORT:-5540}:5540"
    volumes:
      - redisinsight_data:/data
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

  # ============================================================================
  # OBJECT STORAGE
  # ============================================================================

  minio:
    image: minio/minio:latest
    container_name: minio
    env_file:
      - .env.dev
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_REGION: ${MINIO_REGION:-us-east-1}
    command: server /data --console-address ":9001"
    ports:
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
      - "${MINIO_API_PORT:-9002}:9000"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  create-buckets:
    image: minio/mc
    container_name: minio-setup
    env_file:
      - .env.dev
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: /bin/bash
    command: |
      -c "
      set -e
      echo 'Waiting for MinIO to be ready...'
      sleep 15
      
      echo 'Testing MinIO connection...'
      until mc alias set local http://minio:9000 ${MINIO_ROOT_USER:-minio_admin_2024} ${MINIO_ROOT_PASSWORD:-minio_secure_password_2024}; do
        echo 'MinIO not ready yet, waiting 5 seconds...'
        sleep 5
      done
      
      echo 'MinIO is ready, creating buckets...'
      
      # Create buckets from environment variable
      IFS=',' read -ra BUCKETS <<< \"${MINIO_DEFAULT_BUCKETS:-photos,pdf,documents,models,datasets}\"
      for bucket in \"\${BUCKETS[@]}\"; do
        echo \"Creating bucket: \${bucket}\"
        mc mb -p local/\${bucket} || echo \"Bucket \${bucket} already exists\"
      done
      
      echo 'Listing all buckets:'
      mc ls local || echo 'Could not list buckets'
      
      echo 'Bucket creation process completed!'
      "
    restart: "no"

  # ============================================================================
  # ERROR TRACKING
  # ============================================================================

  sentry-migrate:
    image: getsentry/sentry:25.7.0
    container_name: sentry-migrate
    env_file:
      - .env.dev
    environment:
      SENTRY_SECRET_KEY: ${SENTRY_SECRET_KEY}
      DATABASE_URL: ${SENTRY_DATABASE_URL}
      SENTRY_REDIS_HOST: ${SENTRY_REDIS_HOST}
      SENTRY_REDIS_PORT: ${SENTRY_REDIS_PORT}
      SENTRY_REDIS_PASSWORD: ${SENTRY_REDIS_PASSWORD}
    depends_on:
      pgvector:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: |
      bash -c "
      set -e
      echo 'Running Sentry database migrations...'
      sentry upgrade --noinput
      echo 'Creating default superuser...'
      sentry createuser --email admin@naira.local --password admin --superuser --no-input || echo 'User already exists'
      "
    restart: "no"

  sentry:
    image: getsentry/sentry:25.7.0
    container_name: sentry
    env_file:
      - .env.dev
    environment:
      SENTRY_SECRET_KEY: ${SENTRY_SECRET_KEY}
      DATABASE_URL: ${SENTRY_DATABASE_URL}
      SENTRY_REDIS_HOST: ${SENTRY_REDIS_HOST}
      SENTRY_REDIS_PORT: ${SENTRY_REDIS_PORT}
      SENTRY_REDIS_PASSWORD: ${SENTRY_REDIS_PASSWORD}
    ports:
      - "9000:9000"
    depends_on:
      sentry-migrate:
        condition: service_completed_successfully
    command: run web
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/_health/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # ============================================================================
  # WORKFLOW ORCHESTRATION - APACHE AIRFLOW
  # ============================================================================

  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    entrypoint: /bin/bash
    command: |
      -c "
      set -e
      echo 'Checking Airflow version...'
      airflow version
      
      echo 'Initializing Airflow database...'
      airflow db init
      airflow db upgrade
      
      echo 'Creating admin user...'
      airflow users create \
        --username ${_AIRFLOW_WWW_USER_USERNAME} \
        --firstname Admin \
        --lastname User \
        --role Admin \
        --email ${_AIRFLOW_WWW_USER_EMAIL} \
        --password ${_AIRFLOW_WWW_USER_PASSWORD}
      
      echo 'Setting up directories...'
      mkdir -p /sources/{logs,dags,plugins,config}
      chown -R ${AIRFLOW_UID}:${AIRFLOW_GID} /sources/{logs,dags,plugins,config}
      
      echo 'Airflow initialization completed successfully!'
      "
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD}
      _AIRFLOW_WWW_USER_EMAIL: ${_AIRFLOW_WWW_USER_EMAIL}
    user: root
    restart: "no"

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow-webserver
    command: webserver
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    command: scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-worker:
    <<: *airflow-common
    container_name: airflow-worker
    command: celery worker
    healthcheck:
      test: ["CMD-SHELL", 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-triggerer:
    <<: *airflow-common
    container_name: airflow-triggerer
    command: triggerer
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type TriggererJob --hostname "$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  flower:
    <<: *airflow-common
    container_name: flower
    command: celery flower
    ports:
      - "${FLOWER_PORT:-5555}:5555"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  # ============================================================================
  # GRAPH DATABASE
  # ============================================================================

  neo4j:
    image: neo4j:latest
    container_name: neo4j
    env_file:
      - .env.dev
    environment:
      NEO4J_AUTH: ${NEO4J_AUTH}
      NEO4J_PLUGINS: '["apoc"]'
      NEO4J_apoc_export_file_enabled: true
      NEO4J_apoc_import_file_enabled: true
      NEO4J_apoc_import_file_use__neo4j__config: true
      NEO4J_dbms_security_procedures_unrestricted: apoc.*
    ports:
      - "${NEO4J_HTTP_PORT:-7474}:7474"
      - "${NEO4J_BOLT_PORT:-7687}:7687"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_plugins:/plugins
      - neo4j_import:/var/lib/neo4j/import
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "neo4j_secure_password_2024", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # ============================================================================
  # LLM SERVICES
  # ============================================================================

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    env_file:
      - .env.dev
    environment:
      OLLAMA_HOST: ${OLLAMA_HOST:-0.0.0.0}
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # ============================================================================
  # VECTOR DATABASE
  # ============================================================================

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    env_file:
      - .env.dev
    environment:
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
    ports:
      - "${QDRANT_HTTP_PORT:-6333}:6333"
      - "${QDRANT_GRPC_PORT:-6334}:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped

# ============================================================================
# VOLUMES
# ============================================================================

volumes:
  # Database volumes
  pgvector_data:
    driver: local
  pgadmin_data:
    driver: local

  # Cache volumes
  redis_data:
    driver: local
  redisinsight_data:
    driver: local

  # Storage volumes
  minio_data:
    driver: local

  # Graph database volumes
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  neo4j_plugins:
    driver: local
  neo4j_import:
    driver: local

  # AI/ML volumes
  ollama_data:
    driver: local
  qdrant_data:
    driver: local

# ============================================================================
# NETWORKS
# ============================================================================

networks:
  default:
    name: ${COMPOSE_PROJECT_NAME:-naira_stack}_network
    driver: bridge